{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This notebook was used to extract Java methods from GitHub repositories.\n",
        "'''"
      ],
      "metadata": {
        "id": "XlL2j7pSYcle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvX-82iaJjEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01670576-83b5-4438-cc07-d659edfc39a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydriller\n",
            "  Downloading PyDriller-2.7-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from pydriller) (3.1.44)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from pydriller) (2025.1)\n",
            "Requirement already satisfied: types-pytz in /usr/local/lib/python3.11/dist-packages (from pydriller) (2025.1.0.20250204)\n",
            "Collecting lizard (from pydriller)\n",
            "  Downloading lizard-1.17.19-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->pydriller) (4.0.12)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from lizard->pydriller) (2.18.0)\n",
            "Collecting pathspec (from lizard->pydriller)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->pydriller) (5.0.2)\n",
            "Downloading PyDriller-2.7-py3-none-any.whl (36 kB)\n",
            "Downloading lizard-1.17.19-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pathspec, lizard, pydriller\n",
            "Successfully installed lizard-1.17.19 pathspec-0.12.1 pydriller-2.7\n",
            "Collecting javalang\n",
            "  Downloading javalang-0.13.0-py3-none-any.whl.metadata (805 bytes)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from javalang) (1.17.0)\n",
            "Downloading javalang-0.13.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: javalang\n",
            "Successfully installed javalang-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pydriller\n",
        "!pip install javalang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s11PkawhYPLS"
      },
      "outputs": [],
      "source": [
        "#### GHS ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPeaXxjOKqFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0601ba66-fce6-4c8e-cea9-4b36e28fb751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPA publishes dbgsym, you may need to include 'main/debug' component\n",
            "Repository: 'deb https://ppa.launchpadcontent.net/git-core/ppa/ubuntu/ jammy main'\n",
            "Description:\n",
            "The most current stable version of Git for Ubuntu.\n",
            "\n",
            "For release candidates, go to https://launchpad.net/~git-core/+archive/candidate .\n",
            "More info: https://launchpad.net/~git-core/+archive/ubuntu/ppa\n",
            "Adding repository.\n",
            "Press [ENTER] to continue or Ctrl-c to cancel.\n",
            "Adding deb entry to /etc/apt/sources.list.d/git-core-ubuntu-ppa-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/git-core-ubuntu-ppa-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/git-core-ubuntu-ppa.gpg with fingerprint F911AB184317630C59970973E363C90F8F1B6217\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,637 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,318 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,235 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/git-core/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,657 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,799 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,531 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,941 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,660 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,699 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/git-core/ppa/ubuntu jammy/main amd64 Packages [2,957 B]\n",
            "Fetched 28.9 MB in 3s (9,023 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/git-core/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  git-man\n",
            "Suggested packages:\n",
            "  gettext-base git-doc git-email git-gui gitk gitweb git-cvs git-mediawiki git-svn\n",
            "The following packages will be upgraded:\n",
            "  git git-man\n",
            "2 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n",
            "Need to get 9,155 kB of archives.\n",
            "After this operation, 15.7 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/git-core/ppa/ubuntu jammy/main amd64 git amd64 1:2.48.1-0ppa1~ubuntu22.04.1 [6,904 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/git-core/ppa/ubuntu jammy/main amd64 git-man all 1:2.48.1-0ppa1~ubuntu22.04.1 [2,251 kB]\n",
            "Fetched 9,155 kB in 1s (7,373 kB/s)\n",
            "(Reading database ... 124935 files and directories currently installed.)\n",
            "Preparing to unpack .../git_1%3a2.48.1-0ppa1~ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking git (1:2.48.1-0ppa1~ubuntu22.04.1) over (1:2.34.1-1ubuntu1.12) ...\n",
            "Preparing to unpack .../git-man_1%3a2.48.1-0ppa1~ubuntu22.04.1_all.deb ...\n",
            "Unpacking git-man (1:2.48.1-0ppa1~ubuntu22.04.1) over (1:2.34.1-1ubuntu1.12) ...\n",
            "Setting up git-man (1:2.48.1-0ppa1~ubuntu22.04.1) ...\n",
            "Setting up git (1:2.48.1-0ppa1~ubuntu22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!add-apt-repository ppa:git-core/ppa\n",
        "!apt-get update\n",
        "!apt-get install git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "wZvOUyq_GQFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOyEEFLDLDBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "e48e5e3f-2a4a-41a5-bb4c-aea03f963716"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pydriller'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5fa27301b444>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydriller\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjavalang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjavalang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMethodDeclaration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydriller'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from pydriller import Repository\n",
        "import os\n",
        "from javalang.parse import parse\n",
        "from javalang.tree import MethodDeclaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki3dBwJ3XqGf"
      },
      "outputs": [],
      "source": [
        "df_res = pd.read_csv('ghs_results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dFLR9wCXxcF"
      },
      "outputs": [],
      "source": [
        "repoList = []\n",
        "for idx,row in df_res.iterrows():\n",
        "  repoList.append(\"https://www.github.com/{}\".format(row['name']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdPhm715LucJ"
      },
      "source": [
        "#Importance of Collecting High-Quality Data from GitHub Repositories\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "High-quality data is the backbone of training effective and reliable machine learning models, especially for tasks involving code and natural language. GitHub repositories offer a vast amount of real-world, diverse data, making them an invaluable resource for building advanced models like LLMs for software engineering.\n",
        "However, not all repositories are equally relevant or well-maintained. Selecting only relevant repositories ensures that the da\n",
        "ta aligns with the task at hand, minimizing noise and improving the model’s performance. This approach also reduces the risk of introducing low-quality or misleading patterns into the training process, resulting in models that are both robust and practical. Thus, we need to collect source code using specific criteria. An helping hand is provided by the following platform:\n",
        "[GHS](https://seart-ghs.si.usi.ch/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0ys2hMonnA4"
      },
      "outputs": [],
      "source": [
        "from pydriller import Repository\n",
        "import os\n",
        "import csv\n",
        "from javalang.parse import parse\n",
        "from javalang.tree import MethodDeclaration\n",
        "import javalang\n",
        "\n",
        "def extract_methods_from_java(code):\n",
        "    \"\"\"\n",
        "    Extract methods from Java source code using javalang parser.\n",
        "\n",
        "    Args:\n",
        "        code (str): The Java source code.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples containing method names and their full source code.\n",
        "    \"\"\"\n",
        "    methods = []\n",
        "    try:\n",
        "        # Parse the code into an Abstract Syntax Tree (AST)\n",
        "        tree = javalang.parse.parse(code)\n",
        "        lines = code.splitlines()\n",
        "\n",
        "        # Traverse the tree to find method declarations\n",
        "        for _, node in tree.filter(javalang.tree.MethodDeclaration):\n",
        "            method_name = node.name\n",
        "\n",
        "            # Determine the start and end lines of the method\n",
        "            start_line = node.position.line - 1\n",
        "            end_line = None\n",
        "\n",
        "            # Use the body of the method to determine its end position\n",
        "            if node.body:\n",
        "                last_statement = node.body[-1]\n",
        "                if hasattr(last_statement, 'position') and last_statement.position:\n",
        "                    end_line = last_statement.position.line\n",
        "\n",
        "            # Extract method code\n",
        "            if end_line:\n",
        "                method_code = \"\\n\".join(lines[start_line:end_line+1])\n",
        "            else:\n",
        "                # If end_line couldn't be determined, extract up to the end of the file\n",
        "                method_code = \"\\n\".join(lines[start_line:])\n",
        "\n",
        "            methods.append((method_name, method_code))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing Java code: {e}\")\n",
        "    return methods\n",
        "\n",
        "\n",
        "def extract_methods_to_csv_from_master(repo_path, output_csv):\n",
        "    \"\"\"\n",
        "    Extract methods from Java files in the master branch and save them in a CSV file.\n",
        "\n",
        "    Args:\n",
        "        repo_path (str): Path to the Git repository.\n",
        "        output_csv (str): Path to the output CSV file.\n",
        "    \"\"\"\n",
        "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"Commit Hash\", \"File Name\", \"Method Name\", \"Method Code\", \"Commit Link\"])\n",
        "\n",
        "        for commit in Repository(repo_path, only_in_branch=\"master\").traverse_commits():\n",
        "            print(f\"Processing commit: {commit.hash}\")\n",
        "\n",
        "            #We only look into the modified files. In other words, we are looking into the history of the software system by traversing each commit.\n",
        "            #Various Generative AI methods for SD have been trained on data collected in this way; for example bug fixing.\n",
        "            for modified_file in commit.modified_files:\n",
        "                if modified_file.filename.endswith(\".java\") and modified_file.source_code:\n",
        "                    methods = extract_methods_from_java(modified_file.source_code)\n",
        "\n",
        "                    for method_name, method_code in methods:\n",
        "                        commit_link = f\"{repo_path}/commit/{commit.hash}\"\n",
        "                        csv_writer.writerow([commit.hash, modified_file.filename, method_name, method_code, commit_link])\n",
        "\n",
        "                    print(f\"Extracted methods from {modified_file.filename} in commit {commit.hash}\")\n",
        "\n",
        "\n",
        "def extract_methods_to_csv(repo_path, output_csv):\n",
        "    \"\"\"\n",
        "    Extract methods from Java files in a repository and save them in a CSV file.\n",
        "\n",
        "    Args:\n",
        "        repo_path (str): Path to the Git repository.\n",
        "        output_csv (str): Path to the output CSV file.\n",
        "    \"\"\"\n",
        "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"Branch Name\", \"Commit Hash\", \"File Name\", \"Method Name\", \"Method Code\", \"Commit Link\"])\n",
        "\n",
        "        branch_name = \"master\"\n",
        "        for commit in Repository(repo_path, only_in_branch=branch_name).traverse_commits():\n",
        "            print(f\"Processing commit: {commit.hash}\")\n",
        "\n",
        "            for modified_file in commit.modified_files:\n",
        "                if modified_file.filename.endswith(\".java\") and modified_file.source_code:\n",
        "                    methods = extract_methods_from_java(modified_file.source_code)\n",
        "\n",
        "                    for method_name, method_code in methods:\n",
        "                        commit_link = f\"{repo_path}/commit/{commit.hash}\"\n",
        "                        csv_writer.writerow([branch_name, commit.hash, modified_file.filename, method_name, method_code, commit_link])\n",
        "\n",
        "                    print(f\"Extracted methods from {modified_file.filename} in commit {commit.hash}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repoList = repoList[0:4] + [repoList[14]] + [repoList[18]]\n",
        "print(repoList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TIohOegASYt",
        "outputId": "6558c459-6eb2-4d0e-93a9-92dc3972703c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.github.com/qos-ch/slf4j', 'https://www.github.com/jhy/jsoup', 'https://www.github.com/tootallnate/java-websocket', 'https://www.github.com/mpatric/mp3agic', 'https://www.github.com/oshi/oshi', 'https://www.github.com/dreamhead/moco']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for repo in repoList:\n",
        "\n",
        "    fileNameToSave = ''.join(repo.split('github.com')[1:])\n",
        "    fileNameToSave = fileNameToSave.replace('/','_')\n",
        "\n",
        "    # Specify the path to the output CSV file\n",
        "    output_csv_file = \"extracted_methods_{}.csv\".format(fileNameToSave)\n",
        "    # Run the extraction\n",
        "    extract_methods_to_csv_from_master(repo, output_csv_file)\n",
        "\n",
        "\n",
        "    print(repo)"
      ],
      "metadata": {
        "id": "IgXQGttaa5mM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}